import streamlit as st
import openai
import requests
import io
import os
from typing import Optional

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éŸ³å£°è¦ç´„ãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ¤",
    layout="wide"
)

st.title("ğŸ¤ éŸ³å£°è¦ç´„ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AI ãŒè‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„ã‚’è¡Œã„ã¾ã™")

# APIè¨­å®šã®ç¢ºèª
def check_api_keys():
    """API ã‚­ãƒ¼ã®è¨­å®šç¢ºèª"""
    try:
        openai_key = st.secrets["OPENAI_API_KEY"]
        dify_key = st.secrets["DIFY_API_KEY"]
        dify_app_id = st.secrets["DIFY_APP_ID"]
        return openai_key, dify_key, dify_app_id
    except KeyError as e:
        st.error(f"Streamlit Secrets ã« {e} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.info("è¨­å®šæ–¹æ³•: Settings â†’ Secrets ã‹ã‚‰ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        st.code('''
OPENAI_API_KEY = "sk-..."
DIFY_API_KEY = "app-..."
DIFY_APP_ID = "xxxxxxxx"
        ''')
        return None, None, None

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

def split_audio_file(audio_bytes: bytes, max_chunk_size: int = 14 * 1024 * 1024) -> list:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    chunks = []
    total_size = len(audio_bytes)
    
    if total_size <= max_chunk_size:
        return [audio_bytes]
    
    start = 0
    chunk_num = 0
    max_chunks = 10  # æœ€å¤§10ãƒãƒ£ãƒ³ã‚¯
    
    while start < total_size and chunk_num < max_chunks:
        end = min(start + max_chunk_size, total_size)
        chunks.append(audio_bytes[start:end])
        start = end
        chunk_num += 1
    
    return chunks

def transcribe_audio_chunks(chunks: list, openai_key: str) -> str:
    """Whisperã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—"""
    client = openai.OpenAI(api_key=openai_key)
    transcripts = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, chunk in enumerate(chunks):
        status_text.text(f"æ–‡å­—èµ·ã“ã—ä¸­... ({i+1}/{len(chunks)})")
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æº–å‚™
        audio_file = io.BytesIO(chunk)
        audio_file.name = f"audio_chunk_{i+1}.m4a"  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¨­å®š
        
        try:
            # Whisper APIã§æ–‡å­—èµ·ã“ã—
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ja"  # æ—¥æœ¬èªã‚’æŒ‡å®š
            )
            transcripts.append(response.text)
        except Exception as e:
            st.error(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®æ–‡å­—èµ·ã“ã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return ""
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
        progress_bar.progress((i + 1) / len(chunks))
    
    progress_bar.empty()
    status_text.empty()
    
    return " ".join(transcripts)

def send_to_dify(transcript: str, dify_key: str, dify_app_id: str, summary_prompt: str = "") -> Optional[str]:
    """Difyã«æ–‡å­—èµ·ã“ã—çµæœã‚’é€ä¿¡ã—ã¦è¦ç´„ã‚’å–å¾—"""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    if summary_prompt:
        query = f"{summary_prompt}\n\n---\n{transcript}"
    else:
        query = transcript
    
    payload = {
        "query": query,
        "user": "streamlit_user_1"
    }
    
    headers = {
        "Authorization": f"Bearer {dify_key}",
        "X-Dify-App-Id": dify_app_id,
        "Content-Type": "application/json"
    }
    
    try:
        with st.spinner("è¦ç´„ã‚’ç”Ÿæˆä¸­..."):
            response = requests.post(
                "https://api.dify.ai/chat-messages",
                headers=headers,
                json=payload,
                timeout=120
            )
        
        if response.status_code == 200:
            result = response.json()
            return result.get("answer", "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.error(f"Dify API ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"Dify ã¨ã®é€šä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    # API ã‚­ãƒ¼ã®ç¢ºèª
    openai_key, dify_key, dify_app_id = check_api_keys()
    if not all([openai_key, dify_key, dify_app_id]):
        return
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®è¨­å®š
    with st.sidebar:
        st.header("è¨­å®š")
        
        # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        summary_prompt = st.text_area(
            "è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            value="",
            help="ç©ºã®å ´åˆã€Dify Chatflow ã® System Prompt ãŒä½¿ç”¨ã•ã‚Œã¾ã™",
            placeholder="ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’3ã¤ã®ãƒã‚¤ãƒ³ãƒˆã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
        )
        
        st.info("ğŸ’¡ **å¯¾å¿œå½¢å¼**: m4a, mp3, wav, flac, mp4, mpeg, mpga, oga, ogg, webm")
        st.info("ğŸ“ **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: æœ€å¤§200MB")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["m4a", "mp3", "wav", "flac", "mp4", "mpeg", "mpga", "oga", "ogg", "webm"],
        accept_multiple_files=False
    )
    
    if uploaded_file is not None:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
        st.info(f"ğŸ“ **ãƒ•ã‚¡ã‚¤ãƒ«**: {uploaded_file.name} ({file_size_mb:.1f} MB)")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if file_size_mb > 200:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ200MBã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šå°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # å‡¦ç†ãƒœã‚¿ãƒ³
        if st.button("ğŸ¤ æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„ã‚’å®Ÿè¡Œ", type="primary"):
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            user_message = f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_file.name}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ"
            st.session_state.messages.append({"role": "user", "content": user_message})
            
            with st.chat_message("user"):
                st.markdown(user_message)
            
            with st.chat_message("assistant"):
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                audio_bytes = uploaded_file.getvalue()
                
                # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
                st.info("ğŸ”„ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
                chunks = split_audio_file(audio_bytes)
                
                if len(chunks) > 10:
                    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã¾ã™ã€‚10ãƒãƒ£ãƒ³ã‚¯ä»¥ä¸‹ã«ãªã‚‹ã‚ˆã†èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
                    return
                
                st.success(f"âœ… {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
                
                # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                st.info("ğŸ¯ Whisper ã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­...")
                transcript = transcribe_audio_chunks(chunks, openai_key)
                
                if not transcript:
                    st.error("æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return
                
                st.success("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
                
                # æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤ºï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
                with st.expander("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœã‚’è¡¨ç¤º"):
                    st.text_area("æ–‡å­—èµ·ã“ã—", value=transcript, height=200, disabled=True)
                
                # Dify ã§è¦ç´„ç”Ÿæˆ
                summary = send_to_dify(transcript, dify_key, dify_app_id, summary_prompt)
                
                if summary:
                    st.markdown("### ğŸ“Š è¦ç´„çµæœ")
                    st.markdown(summary)
                    
                    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    st.session_state.messages.append({"role": "assistant", "content": summary})
                else:
                    st.error("è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
