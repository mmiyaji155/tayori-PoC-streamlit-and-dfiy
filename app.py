import streamlit as st
import openai, json, requests, io, os, tempfile
from typing import Optional
from pydub import AudioSegment

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ç”»é¢è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="éŸ³å£°è¦ç´„ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ¤", layout="wide")
st.title("ğŸ“ICè¦ç´„ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AI ãŒ **æ–‡å­—èµ·ã“ã— â†’ è¦ç´„** ã‚’è¡Œã„ã€ãã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™ã€‚")

with st.expander("ğŸ“– ä½¿ã„æ–¹", expanded=False):
    st.markdown("""
1. **éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**  
2. **æ–‡å­—èµ·ã“ã—**â†’ **è¦ç´„ç”Ÿæˆ**  
3. è¦ç´„å†…å®¹ã«ã¤ã„ã¦ãƒãƒ£ãƒƒãƒˆã§è³ªå•
""")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_api_keys():
    try:
        return st.secrets["OPENAI_API_KEY"], st.secrets["DIFY_API_KEY"]
    except KeyError as e:
        st.error(f"Secrets ã« {e} ãŒã‚ã‚Šã¾ã›ã‚“"); return None, None

def compress_audio(b: bytes, fname: str, target_mb=24) -> bytes:
    ext = fname.split('.')[-1].lower() if '.' in fname else 'mp3'
    with tempfile.NamedTemporaryFile(suffix=f'.{ext}', delete=False) as t_in:
        t_in.write(b); in_path = t_in.name
    try:
        audio = AudioSegment.from_file(in_path)
        ratio = (target_mb*1024*1024*0.9) / len(b)
        br = "128k" if ratio>=.7 else "96k" if ratio>=.5 else "64k" if ratio>=.3 else "32k"
        if br in ("64k","32k"): audio = audio.set_frame_rate(16000 if br=="32k" else 22050)
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as t_out:
            out_path = t_out.name
        audio.export(out_path, format="mp3", bitrate=br, parameters=["-q:a","9"])
        return open(out_path,'rb').read()
    finally:
        for p in (in_path, locals().get('out_path')):
            if p and os.path.exists(p): os.unlink(p)

def transcribe(chunks, key, fname):
    st.info("ğŸ“ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹â€¦")
    client = openai.OpenAI(api_key=key)
    texts = []
    for i, c in enumerate(chunks):
        f = io.BytesIO(c); f.name = f"chunk{i}.{fname.split('.')[-1]}"
        r = client.audio.transcriptions.create(model="whisper-1", file=f, language="ja")
        texts.append(r.text)
    st.success("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
    return " ".join(texts)

def ask_dify(query: str, dify_key: str,
             conv_id: str = "", user_id: str = "streamlit_user_1") -> tuple[Optional[str], Optional[str]]:

    headers = {"Authorization": f"Bearer {dify_key}", "Content-Type": "application/json"}
    payload = {"query": query, "inputs": {}, "response_mode": "streaming",
               "conversation_id": conv_id, "user": user_id}

    with st.spinner("ğŸŒ€ è¦ç´„ã‚’ç”Ÿæˆä¸­â€¦"):
        r = requests.post("https://api.dify.ai/v1/chat-messages",
                          headers=headers, json=payload, timeout=120, stream=True)

    if r.status_code == 200 and r.headers.get("Content-Type","").startswith("text/event-stream"):
        chunks, new_id = [], conv_id
        for line in r.iter_lines(decode_unicode=True):
            if not line.startswith("data:"): continue
            obj = json.loads(line[5:].strip())
            if obj.get("event") == "message":
                chunks.append(obj.get("answer","")); new_id = obj.get("conversation_id", conv_id)
            elif obj.get("event") == "error":
                st.error(f"Dify error: {obj.get('message') or obj}"); return None, conv_id
            elif obj.get("event") == "message_end": break
        return "".join(chunks), new_id

    if r.status_code == 200:
        js = r.json(); return js.get("answer",""), js.get("conversation_id","")
    try:
        st.error(f"Dify API {r.status_code}: {r.json()}")
    except:
        st.error(f"Dify API {r.status_code}: {r.text[:200]}")
    return None, None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state: st.session_state.messages = []
if "conversation_id" not in st.session_state: st.session_state.conversation_id = ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ãƒ¡ã‚¤ãƒ³ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    openai_key, dify_key = check_api_keys()
    if not all([openai_key, dify_key]): return

    # â”€ sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar:
        st.header("ğŸ”° ã¯ã˜ã‚ã«")

        # â˜… NEW: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹ã® 3 ã‚¹ãƒ†ãƒƒãƒ—æ‰‹é †
        st.markdown(
            """
### ğŸš€ ã‹ã‚“ãŸã‚“ 3 ã‚¹ãƒ†ãƒƒãƒ—
1. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ â†’ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**  
   - m4a / mp3 / wav / flac / mp4 â€¦ ä¸»è¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œ  
   - 25â€¯MB è¶…ãªã‚‰è‡ªå‹•ã§ã‚µã‚¤ã‚ºèª¿æ•´ã—ã¾ã™
2. **è‡ªå‹•å‡¦ç†ã‚’å¾…ã¤ã ã‘**  
   - Whisper ãŒæ–‡å­—èµ·ã“ã— â†’ Dify ãŒè¦ç´„ã‚’ç”Ÿæˆ  
   - ç”ŸæˆãŒçµ‚ã‚ã‚‹ã¨è¦ç´„ãŒãƒãƒ£ãƒƒãƒˆã«è¡¨ç¤ºã•ã‚Œã¾ã™
3. **ãƒãƒ£ãƒƒãƒˆã§ã‚„ã‚Šå–ã‚Š**  
   - è¦ç´„ã‚’èª­ã‚“ã§ã€Œã‚‚ã£ã¨è©³ã—ãã€ã€Œâ—¯â—¯ã‚’å‰Šé™¤ã—ã¦ã€ãªã©è‡ªç”±ã«è³ªå•ãƒ»ä¿®æ­£æŒ‡ç¤º  
   - è¿½åŠ è³ªå•ã«ã‚‚è¦ç´„å†…å®¹ã‚’è¸ã¾ãˆã¦å›ç­”ã—ã¾ã™
""",
            unsafe_allow_html=True
        )

        # â˜… NEW: ã§ãã‚‹ã“ã¨ãƒªã‚¹ãƒˆ
        st.markdown(
            """
### ğŸ’¡ ã“ã®ã‚¢ãƒ—ãƒªã§å‡ºæ¥ã‚‹ã“ã¨
- **ãƒã‚¤ãƒ³ãƒˆè¦ç´„**: é•·ã„éŸ³å£°ã§ã‚‚è¦ç‚¹ã ã‘ã‚’èª­ã¿ã‚„ã™ãæŠ½å‡º  
- **ãƒ•ã‚©ãƒ­ãƒ¼è³ªå•**: è¦ç´„ã‚’ææ–™ã«è¿½åŠ ã®è³ªå•ã‚„æ·±æ˜ã‚ŠãŒå¯èƒ½  
- **è¦ç´„ã®ä¿®æ­£æŒ‡ç¤º**: ã€Œç®‡æ¡æ›¸ãã‚’å¢—ã‚„ã™ã€ã€Œå°‚é–€ç”¨èªã‚’å‰Šã‚‹ã€ãªã©ãƒªãƒ©ã‚¤ãƒˆè¦æ±‚  
- **å±¥æ­´ç¶­æŒ**: åŒã˜ç”»é¢ã§ä¼šè©±ã‚’ç¶šã‘ã‚‹ã¨éå»ã®è¦ç´„ã‚’è¸ã¾ãˆã¦å›ç­”
""",
            unsafe_allow_html=True
        )

        # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›ï¼ˆä»»æ„ï¼‰
        prompt = st.text_area(
            "ğŸ–‹ï¸ è¿½åŠ è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä»»æ„ï¼‰",
            "",
            height=120,
            placeholder="ç‰¹åˆ¥ã«æŒ‡ç¤ºã—ãŸã„ã“ã¨ãŒã‚ã‚Œã°å…¥åŠ›ã—ã¦ãã ã•ã„",
        )

    # â”€ chat history
    for m in st.session_state.messages:
        with st.chat_message(m["role"]): st.markdown(m["content"])

    # â”€ file upload
    uf = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=[
        "m4a","mp3","wav","flac","mp4","mpeg","mpga","oga","ogg","webm"])
    if uf and st.button("ğŸ¤ æ–‡å­—èµ·ã“ã— â†’ è¦ç´„"):
        user_msg = f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« **{uf.name}** ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ"
        st.session_state.messages.append({"role":"user","content":user_msg})
        with st.chat_message("user"): st.markdown(user_msg)

        with st.chat_message("assistant"):
            b = uf.getvalue()
            if len(b) > 25*1024*1024:
                st.info("25â€¯MB è¶…ã‚’æ¤œçŸ¥ â†’ åœ§ç¸®"); b = compress_audio(b, uf.name)
            transcript = transcribe([b], openai_key, uf.name)
            q = f"{prompt}\n\n---\n{transcript}" if prompt else transcript
            answer, cid = ask_dify(q, dify_key)
            if answer:
                st.markdown(answer)
                st.session_state.messages.append({"role":"assistant","content":answer})
                st.session_state.conversation_id = cid
            else:
                st.error("è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

    # â”€ question mode
    if st.session_state.conversation_id:
        qtxt = st.chat_input("è¦ç´„ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„â€¦")
        if qtxt:
            st.session_state.messages.append({"role":"user","content":qtxt})
            with st.chat_message("user"): st.markdown(qtxt)
            with st.chat_message("assistant"):
                a, cid = ask_dify(qtxt, dify_key, st.session_state.conversation_id)
                if a:
                    st.markdown(a); st.session_state.messages.append({"role":"assistant","content":a})
                    st.session_state.conversation_id = cid
                else:
                    st.error("å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
